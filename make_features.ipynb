{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide whether or not running on Kaggle\n",
    "import os\n",
    "KAGGLE_RUN = True\n",
    "if os.path.isdir('/home/ubuntu'):\n",
    "    KAGGLE_RUN = False\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import datatable as dt\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "if not KAGGLE_RUN:\n",
    "    sys.path.insert(0, './input')\n",
    "    import local_work\n",
    "    \n",
    "import riiideducation\n",
    "\n",
    "# Boto3 Setup and Download Files\n",
    "if not KAGGLE_RUN:\n",
    "    local_work = local_work.local_work()\n",
    "    local_work.download_riiid_files()\n",
    "\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(KAGGLE_RUN):\n",
    "    # Load questions\n",
    "    if not KAGGLE_RUN:\n",
    "        questions_df = local_work.get_questions_data()\n",
    "        question_cmnts = pd.read_csv('./input/question_cmnts_v5.csv')\n",
    "    else:   \n",
    "        questions_df = pd.read_csv('../input/riiid-test-answer-prediction/questions.csv')\n",
    "        question_cmnts = pd.read_csv('../input/question-cmnts-v5/question_cmnts_v5.csv')\n",
    "        \n",
    "    # Add Communities to questions\n",
    "    question_cmnts.columns = ['question_id', 'community']\n",
    "    questions_df = questions_df.merge(question_cmnts, on = 'question_id', how = 'left')\n",
    "    \n",
    "    # Get tags of questions\n",
    "    inv_rows = questions_df[questions_df['tags'].apply(type) == float].index\n",
    "    questions_df.at[inv_rows, 'tags'] = ''\n",
    "    questions_df['tags'] = questions_df['tags'].apply(lambda x: np.array(x.split()).astype(int))\n",
    "    questions_df['n_tags'] = questions_df['tags'].str.len()\n",
    "    questions_df.loc[questions_df.n_tags == 0, 'n_tags'] = 1\n",
    "    questions_df['tag_1'] = questions_df['tags'].map(lambda x: x[0] if len(x) > 0 else np.nan)\n",
    "    questions_df['tag_2'] = questions_df['tags'].map(lambda x: x[1] if len(x) > 1 else np.nan)\n",
    "    questions_df['tag_3'] = questions_df['tags'].map(lambda x: x[2] if len(x) > 2 else np.nan)\n",
    "        \n",
    "    # Change questions dtypes\n",
    "    questions_df['part'] = questions_df['part'].astype(np.int32)\n",
    "    questions_df['bundle_id'] = questions_df['bundle_id'].astype(np.int32)\n",
    "    questions_df['community'] = questions_df['community'].astype(np.int8)\n",
    "    \n",
    "    return(questions_df)\n",
    "\n",
    "def get_cond_probs(KAGGLE_RUN):\n",
    "    # Load conditional probabilities\n",
    "    if KAGGLE_RUN:\n",
    "        with open('../input/finalmodels/cond_probs.pickle', 'rb') as handle:\n",
    "            cond_probs =  pickle.load(handle)\n",
    "    else:\n",
    "        with open('./output/cond_probs.pickle', 'rb') as handle:\n",
    "            cond_probs =  pickle.load(handle)\n",
    "    return(cond_probs)\n",
    "\n",
    "# Funcion for user stats with loops\n",
    "def add_features(df, features_dicts, cond_probs, KAGGLE_RUN, is_inference):\n",
    "    \n",
    "            \n",
    "    # -----------------------------------------------------------------------\n",
    "    # Get feature dicts\n",
    "    d_answered_correctly_u_count = features_dicts['d_answered_correctly_u_count']\n",
    "    d_answered_correctly_u_sum = features_dicts['d_answered_correctly_u_sum']\n",
    "    d_answered_correctly_prev10_u = features_dicts['d_answered_correctly_prev10_u']\n",
    "    d_elapsed_time_u_sum = features_dicts['d_elapsed_time_u_sum']\n",
    "    d_explanation_u_sum = features_dicts['d_explanation_u_sum']\n",
    "    d_answered_correctly_q_count = features_dicts['d_answered_correctly_q_count']\n",
    "    d_answered_correctly_q_sum = features_dicts['d_answered_correctly_q_sum']\n",
    "    d_elapsed_time_q_sum = features_dicts['d_elapsed_time_q_sum']\n",
    "    d_explanation_ac_q_count = features_dicts['d_explanation_ac_q_count']\n",
    "    d_answered_correctly_uq = features_dicts['d_answered_correctly_uq']\n",
    "    d_timestamp_u = features_dicts['d_timestamp_u']\n",
    "    d_timestamp_u_incorrect = features_dicts['d_timestamp_u_incorrect']\n",
    "    d_answered_correctly_up_sum = features_dicts['d_answered_correctly_up_sum']\n",
    "    d_answered_correctly_up_count = features_dicts['d_answered_correctly_up_count']\n",
    "    d_answered_correctly_uc_count = features_dicts['d_answered_correctly_uc_count']\n",
    "    d_answered_correctly_uc_sum = features_dicts['d_answered_correctly_uc_sum']\n",
    "    d_answered_correctly_ut_count = features_dicts['d_answered_correctly_ut_count']\n",
    "    d_answered_correctly_ut_sum = features_dicts['d_answered_correctly_ut_sum']\n",
    "    d_lectures_u_count = features_dicts['d_lectures_u_count']\n",
    "    d_uq_prev = features_dicts['d_uq_prev']\n",
    "    \n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    # Client features\n",
    "    answered_correctly_u_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    answered_correctly_prev10_u_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    answered_correctly_prev5_u_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    elapsed_time_u_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    explanation_u_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    timestamp_u_recency_1 = np.zeros(len(df), dtype = np.float32)\n",
    "    timestamp_u_recency_2 = np.zeros(len(df), dtype = np.float32)\n",
    "    timestamp_u_recency_3 = np.zeros(len(df), dtype = np.float32)\n",
    "    timestamp_u_incorrect_recency = np.zeros(len(df), dtype = np.float32)\n",
    "    \n",
    "    lectures_u_count = np.zeros(len(df), dtype = np.int32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Question features\n",
    "    answered_correctly_q_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    elapsed_time_q_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    explanation_q_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # User Question\n",
    "    answered_correctly_uq_count = np.zeros(len(df), dtype = np.int32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # User Part\n",
    "    answered_correctly_up_count = np.zeros(len(df), dtype = np.int32)\n",
    "    answered_correctly_up_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # User Community\n",
    "    answered_correctly_uc_count = np.zeros(len(df), dtype = np.int32)\n",
    "    answered_correctly_uc_avg = np.zeros(len(df), dtype = np.float32)    \n",
    "    # -----------------------------------------------------------------------\n",
    "    # User Tags\n",
    "    answered_correctly_ut_cum_count = np.zeros(len(df), dtype = np.int32)\n",
    "    answered_correctly_ut_cum_sum = np.zeros(len(df), dtype = np.int)\n",
    "    answered_correctly_ut_cum_avg = np.zeros(len(df), dtype = np.float)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # User Questions\n",
    "    cond_uq_prob = np.zeros(len(df), dtype = np.float)\n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    \n",
    "    DF_NROW = df.shape[0]\n",
    "    for num, row in enumerate(df[['user_id'\n",
    "                                  ,'answered_correctly'\n",
    "                                  ,'content_id'\n",
    "                                  ,'prior_question_elapsed_time'\n",
    "                                  ,'prior_question_had_explanation'\n",
    "                                  ,'timestamp'\n",
    "                                  ,'part'\n",
    "                                  ,'community'\n",
    "                                  ,'tags' \n",
    "                                  ,'content_type_id' # 9\n",
    "                                 ]].values):\n",
    "        \n",
    "        if DF_NROW > 5000000 and not KAGGLE_RUN:\n",
    "            if num % 10000000 == 0:\n",
    "                print('Progress: ' + str(round(num/DF_NROW, 3)))\n",
    "                \n",
    "        if row[9] == 1:\n",
    "            # Lecture updates\n",
    "            # ------------------------------------------------------------------\n",
    "            d_lectures_u_count[row[0]] += 1\n",
    "            \n",
    "        else:\n",
    "            # Client features assignation\n",
    "            # ------------------------------------------------------------------\n",
    "            if d_answered_correctly_u_count[row[0]] != 0:\n",
    "                answered_correctly_u_avg[num] = d_answered_correctly_u_sum[row[0]] /\\\n",
    "                                                    d_answered_correctly_u_count[row[0]]\n",
    "                elapsed_time_u_avg[num] = d_elapsed_time_u_sum[row[0]] / d_answered_correctly_u_count[row[0]]\n",
    "                explanation_u_avg[num] = d_explanation_u_sum[row[0]] / d_answered_correctly_u_count[row[0]]\n",
    "            else:\n",
    "                answered_correctly_u_avg[num] = np.nan\n",
    "                elapsed_time_u_avg[num] = np.nan\n",
    "                explanation_u_avg[num] = np.nan\n",
    "\n",
    "            if len(d_timestamp_u[row[0]]) == 0:\n",
    "                timestamp_u_recency_1[num] = np.nan\n",
    "                timestamp_u_recency_2[num] = np.nan\n",
    "                timestamp_u_recency_3[num] = np.nan\n",
    "            elif len(d_timestamp_u[row[0]]) == 1:\n",
    "                timestamp_u_recency_1[num] = row[5] - d_timestamp_u[row[0]][0]\n",
    "                timestamp_u_recency_2[num] = np.nan\n",
    "                timestamp_u_recency_3[num] = np.nan\n",
    "            elif len(d_timestamp_u[row[0]]) == 2:\n",
    "                timestamp_u_recency_1[num] = row[5] - d_timestamp_u[row[0]][1]\n",
    "                timestamp_u_recency_2[num] = row[5] - d_timestamp_u[row[0]][0]\n",
    "                timestamp_u_recency_3[num] = np.nan\n",
    "            elif len(d_timestamp_u[row[0]]) == 3:\n",
    "                timestamp_u_recency_1[num] = row[5] - d_timestamp_u[row[0]][2]\n",
    "                timestamp_u_recency_2[num] = row[5] - d_timestamp_u[row[0]][1]\n",
    "                timestamp_u_recency_3[num] = row[5] - d_timestamp_u[row[0]][0]\n",
    "\n",
    "            if len(d_timestamp_u_incorrect[row[0]]) == 0:\n",
    "                timestamp_u_incorrect_recency[num] = np.nan\n",
    "            else:\n",
    "                timestamp_u_incorrect_recency[num] = row[5] - d_timestamp_u_incorrect[row[0]][0]\n",
    "\n",
    "            # prev10 and prev5 will behave a little differently in the beginning\n",
    "            if len(d_answered_correctly_prev10_u[row[0]]) == 0:\n",
    "                answered_correctly_prev10_u_avg[num] = np.nan\n",
    "            else:\n",
    "                answered_correctly_prev10_u_avg[num] = sum(d_answered_correctly_prev10_u[row[0]])/\\\n",
    "                                                        len(d_answered_correctly_prev10_u[row[0]])\n",
    "            if len(d_answered_correctly_prev10_u[row[0]]) > 5:\n",
    "                answered_correctly_prev5_u_avg[num] = sum(d_answered_correctly_prev10_u[row[0]][-5:])/5\n",
    "            else:\n",
    "                answered_correctly_prev5_u_avg[num] = np.nan\n",
    "                \n",
    "            # Lecture assignation\n",
    "            lectures_u_count[num] = d_lectures_u_count[row[0]]\n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Question features assignation\n",
    "            if d_answered_correctly_q_count[row[2]] != 0:\n",
    "                answered_correctly_q_avg[num] = d_answered_correctly_q_sum[row[2]] / d_answered_correctly_q_count[row[2]]\n",
    "                elapsed_time_q_avg[num] = d_elapsed_time_q_sum[row[2]] / d_answered_correctly_q_count[row[2]]\n",
    "                explanation_q_avg[num] = d_explanation_ac_q_count[row[2]] / d_answered_correctly_q_count[row[2]]\n",
    "            else:\n",
    "                answered_correctly_q_avg[num] = np.nan\n",
    "                elapsed_time_q_avg[num] = np.nan\n",
    "                explanation_q_avg[num] = np.nan\n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Question assignation\n",
    "            answered_correctly_uq_count[num] = d_answered_correctly_uq[row[0]][row[2]]\n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Part assignation\n",
    "            answered_correctly_up_count[num] = d_answered_correctly_up_count[row[0]][row[6]]\n",
    "            if d_answered_correctly_up_count[row[0]][row[6]] == 0:\n",
    "                answered_correctly_up_avg[num] = np.nan\n",
    "            else:\n",
    "                answered_correctly_up_avg[num] = d_answered_correctly_up_sum[row[0]][row[6]] /\\\n",
    "                                                    d_answered_correctly_up_count[row[0]][row[6]]\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Community assignation\n",
    "            answered_correctly_uc_count[num] = d_answered_correctly_uc_count[row[0]][row[7]]\n",
    "            if d_answered_correctly_uc_count[row[0]][row[7]] == 0:\n",
    "                answered_correctly_uc_avg[num] = np.nan\n",
    "            else:\n",
    "                answered_correctly_uc_avg[num] = d_answered_correctly_uc_sum[row[0]][row[7]] /\\\n",
    "                                                    d_answered_correctly_uc_count[row[0]][row[7]]  \n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Tag assignation\n",
    "            for t in row[8]:\n",
    "                answered_correctly_ut_cum_count[num] += d_answered_correctly_ut_count[row[0]][t]\n",
    "                answered_correctly_ut_cum_sum[num] += d_answered_correctly_ut_sum[row[0]][t]\n",
    "\n",
    "            if answered_correctly_ut_cum_count[num] == 0:\n",
    "                answered_correctly_ut_cum_avg[num] = np.nan\n",
    "            else:\n",
    "                answered_correctly_ut_cum_avg[num] = answered_correctly_ut_cum_sum[num] /\\\n",
    "                                                        answered_correctly_ut_cum_count[num]   \n",
    "                \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client question assignation\n",
    "            \n",
    "            # If this is a question we have engineered\n",
    "            if row[2] in cond_probs['content_id_keys'].keys():\n",
    "                \n",
    "                # If the user has answered the corresponding previous question\n",
    "                tmp_idx = cond_probs['content_id_keys'][row[2]]\n",
    "                tmp_prev_id = cond_probs['content_id_prev'][tmp_idx]\n",
    "                if tmp_prev_id in d_uq_prev[row[0]].keys():\n",
    "                    \n",
    "                    # Assign the associated probability\n",
    "                    tmp_prev_ac = d_uq_prev[row[0]][tmp_prev_id]\n",
    "                    if tmp_prev_ac == 0:\n",
    "                        cond_uq_prob[num] = cond_probs['prev_wrong_current_mean'][tmp_idx]\n",
    "                    elif tmp_prev_ac == 1:\n",
    "                        cond_uq_prob[num] = cond_probs['prev_right_current_mean'][tmp_idx]\n",
    "                    elif tmp_prev_ac == -1:\n",
    "                        cond_uq_prob[num] = np.nan\n",
    "                        print('Unexpected output in Client Question Assignation')\n",
    "                        print(tmp_idx)\n",
    "                        print(tmp_prev_id)\n",
    "                        print(tmp_prev_ac)                                            \n",
    "                else:\n",
    "                    cond_uq_prob[num] = np.nan\n",
    "            else:\n",
    "                cond_uq_prob[num] = np.nan\n",
    "                \n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client features updates\n",
    "            d_answered_correctly_u_count[row[0]] += 1\n",
    "            d_elapsed_time_u_sum[row[0]] += row[3]\n",
    "            d_explanation_u_sum[row[0]] += int(row[4])\n",
    "            if len(d_timestamp_u[row[0]]) == 3:\n",
    "                d_timestamp_u[row[0]].pop(0)\n",
    "            d_timestamp_u[row[0]].append(row[5])\n",
    "            # ------------------------------------------------------------------\n",
    "            # Question features updates\n",
    "            d_answered_correctly_q_count[row[2]] += 1\n",
    "            d_elapsed_time_q_sum[row[2]] += row[3]\n",
    "            d_explanation_ac_q_count[row[2]] += int(row[4])\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Question updates\n",
    "            d_answered_correctly_uq[row[0]][row[2]] += 1\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Part updates\n",
    "            d_answered_correctly_up_count[row[0]][row[6]] += 1 \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Community updates\n",
    "            d_answered_correctly_uc_count[row[0]][row[7]] += 1    \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Tag updates\n",
    "            for t in row[8]:\n",
    "                d_answered_correctly_ut_count[row[0]][t] += 1            \n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Flag for training and inference. Note: this is almost identical to update_features()\n",
    "            if not is_inference:\n",
    "                # ------------------------------------------------------------------\n",
    "                # Client question updates\n",
    "                if row[2] in cond_probs['content_id_prev']:\n",
    "                    if d_uq_prev[row[0]][row[2]] == -1: # User has not answered question                    \n",
    "                        d_uq_prev[row[0]][row[2]] = row[1]\n",
    "\n",
    "                # ------------------------------------------------------------------\n",
    "                # Client features updates\n",
    "                d_answered_correctly_u_sum[row[0]] += row[1]\n",
    "                if row[1] == 0:\n",
    "                    if len(d_timestamp_u_incorrect[row[0]]) == 1:\n",
    "                        d_timestamp_u_incorrect[row[0]].pop(0)\n",
    "                    d_timestamp_u_incorrect[row[0]].append(row[5])\n",
    "\n",
    "                if len(d_answered_correctly_prev10_u[row[0]]) == 10:\n",
    "                    d_answered_correctly_prev10_u[row[0]].pop(0)\n",
    "                d_answered_correctly_prev10_u[row[0]].append(row[1])                \n",
    "\n",
    "                # ------------------------------------------------------------------\n",
    "                # Question features updates\n",
    "                d_answered_correctly_q_sum[row[2]] += row[1]\n",
    "\n",
    "                # ------------------------------------------------------------------\n",
    "                # Client Part features updates\n",
    "                d_answered_correctly_up_sum[row[0]][row[6]] += row[1]\n",
    "\n",
    "                # ------------------------------------------------------------------\n",
    "                # Client Community features updates\n",
    "                d_answered_correctly_uc_sum[row[0]][row[7]] += row[1]\n",
    "                \n",
    "                # ------------------------------------------------------------------\n",
    "                # Client Community tag updates                \n",
    "                for t in row[8]:\n",
    "                    d_answered_correctly_ut_sum[row[0]][t] += row[1]                 \n",
    "\n",
    "                # ------------------------------------------------------------------\n",
    "             \n",
    "    # END FOR LOOP\n",
    "    \n",
    "    user_df = pd.DataFrame({'answered_correctly_u_avg': answered_correctly_u_avg\n",
    "                            ,'elapsed_time_u_avg': elapsed_time_u_avg\n",
    "                            ,'explanation_u_avg': explanation_u_avg\n",
    "                            ,'answered_correctly_q_avg': answered_correctly_q_avg\n",
    "                            ,'answered_correctly_prev10_u_avg': answered_correctly_prev10_u_avg\n",
    "                            ,'answered_correctly_prev5_u_avg': answered_correctly_prev5_u_avg\n",
    "                            ,'elapsed_time_q_avg': elapsed_time_q_avg\n",
    "                            ,'explanation_q_avg': explanation_q_avg\n",
    "                            ,'answered_correctly_uq_count': answered_correctly_uq_count\n",
    "                            ,'timestamp_u_recency_1': timestamp_u_recency_1\n",
    "                            ,'timestamp_u_recency_2': timestamp_u_recency_2\n",
    "                            ,'timestamp_u_recency_3': timestamp_u_recency_3\n",
    "                            ,'timestamp_u_incorrect_recency': timestamp_u_incorrect_recency\n",
    "                            ,'answered_correctly_up_avg' : answered_correctly_up_avg\n",
    "                            ,'answered_correctly_up_count' : answered_correctly_up_count\n",
    "                            ,'answered_correctly_uc_avg' : answered_correctly_uc_avg\n",
    "                            ,'answered_correctly_uc_count' : answered_correctly_uc_count\n",
    "                            ,'answered_correctly_ut_cum_count' : answered_correctly_ut_cum_count \n",
    "                            ,'answered_correctly_ut_cum_avg' : answered_correctly_ut_cum_avg\n",
    "                            ,'lectures_u_count' : lectures_u_count\n",
    "                            ,'cond_uq_prob' : cond_uq_prob\n",
    "                           })\n",
    "    \n",
    "    # Only need to concat rows if building a model or inferring\n",
    "    if (not KAGGLE_RUN) or is_inference:\n",
    "        df = pd.concat([df, user_df], axis = 1)\n",
    "        \n",
    "    # Return\n",
    "    return df\n",
    "        \n",
    "def update_features(df, features_dicts, cond_probs):\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Get feature dicts\n",
    "    d_answered_correctly_u_sum = features_dicts['d_answered_correctly_u_sum']\n",
    "    d_answered_correctly_q_sum = features_dicts['d_answered_correctly_q_sum']\n",
    "    d_timestamp_u_incorrect = features_dicts['d_timestamp_u_incorrect']\n",
    "    d_answered_correctly_prev10_u = features_dicts['d_answered_correctly_prev10_u']\n",
    "    d_answered_correctly_up_sum = features_dicts['d_answered_correctly_up_sum']\n",
    "    d_answered_correctly_uc_sum = features_dicts['d_answered_correctly_uc_sum']\n",
    "    d_answered_correctly_ut_sum = features_dicts['d_answered_correctly_ut_sum']\n",
    "    d_uq_prev = features_dicts['d_uq_prev']\n",
    "    \n",
    "    for row in df[['user_id'\n",
    "                   ,'answered_correctly'\n",
    "                   ,'content_id'\n",
    "                   ,'content_type_id'\n",
    "                   ,'timestamp'\n",
    "                   ,'part'\n",
    "                   ,'community'\n",
    "                   ,'tags' # 7\n",
    "                  ]].values:\n",
    "        if row[3] == 0:\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client question updates\n",
    "            if row[2] in cond_probs['content_id_prev']:\n",
    "                if d_uq_prev[row[0]][row[2]] == -1: # User has not answered question                    \n",
    "                    d_uq_prev[row[0]][row[2]] = row[1]\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client features updates\n",
    "            d_answered_correctly_u_sum[row[0]] += row[1]\n",
    "            if row[1] == 0:\n",
    "                if len(d_timestamp_u_incorrect[row[0]]) == 1:\n",
    "                    d_timestamp_u_incorrect[row[0]].pop(0)\n",
    "                d_timestamp_u_incorrect[row[0]].append(row[4])\n",
    "                \n",
    "            if len(d_answered_correctly_prev10_u[row[0]]) == 10:\n",
    "                d_answered_correctly_prev10_u[row[0]].pop(0)\n",
    "            d_answered_correctly_prev10_u[row[0]].append(row[1])                   \n",
    "            # ------------------------------------------------------------------\n",
    "            # Question features updates\n",
    "            d_answered_correctly_q_sum[row[2]] += row[1]\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Part features updates\n",
    "            d_answered_correctly_up_sum[row[0]][row[5]] += row[1]\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Community features updates\n",
    "            d_answered_correctly_uc_sum[row[0]][row[6]] += row[1]\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Community tag updates  \n",
    "            for t in row[7]:\n",
    "                d_answered_correctly_ut_sum[row[0]][t] += row[1]               \n",
    "\n",
    "def read_and_preprocess(KAGGLE_RUN):\n",
    "\n",
    "    # Make feature_dicts dictionary for easy passing between functions\n",
    "    features_dicts = {\n",
    "        # Client dictionaries\n",
    "        'd_answered_correctly_u_count': defaultdict(int)\n",
    "        ,'d_answered_correctly_u_sum': defaultdict(int)\n",
    "        ,'d_answered_correctly_prev10_u': defaultdict(list)\n",
    "        ,'d_elapsed_time_u_sum': defaultdict(int)\n",
    "        ,'d_explanation_u_sum': defaultdict(int)\n",
    "        ,'d_timestamp_u': defaultdict(list)\n",
    "        ,'d_timestamp_u_incorrect': defaultdict(list)\n",
    "        ,'d_lectures_u_count': defaultdict(int)\n",
    "        \n",
    "        # Question Dictionaries\n",
    "        ,'d_answered_correctly_q_count': defaultdict(int)\n",
    "        ,'d_answered_correctly_q_sum': defaultdict(int)\n",
    "        ,'d_elapsed_time_q_sum': defaultdict(int)\n",
    "        ,'d_explanation_ac_q_count': defaultdict(int)\n",
    "        \n",
    "        # Client Question dictionary (how many times has the client seen the question)\n",
    "        ,'d_answered_correctly_uq': defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        # Client Part dictionary\n",
    "        ,'d_answered_correctly_up_count': defaultdict(lambda: defaultdict(int))\n",
    "        ,'d_answered_correctly_up_sum': defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        # Client Community Dictionary\n",
    "        ,'d_answered_correctly_uc_count': defaultdict(lambda: defaultdict(int))\n",
    "        ,'d_answered_correctly_uc_sum' : defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        # Client Tag Dictionary\n",
    "        ,'d_answered_correctly_ut_count': defaultdict(lambda: defaultdict(int))\n",
    "        ,'d_answered_correctly_ut_sum': defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        # Previous questions dictionaries\n",
    "        ,'d_uq_prev' : defaultdict(lambda: defaultdict(lambda: int(-1))) #{user_id : {question_id : ac}}\n",
    "    }\n",
    "    \n",
    "    # Load questions and cond_probs\n",
    "    questions_df = get_questions(KAGGLE_RUN)\n",
    "    cond_probs = get_cond_probs(KAGGLE_RUN)\n",
    "        \n",
    "    # Need to load all columns when batching\n",
    "    train_cols = ['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
    "               'task_container_id', 'user_answer', 'answered_correctly',\n",
    "               'prior_question_elapsed_time', 'prior_question_had_explanation']\n",
    "    \n",
    "    # Columns we need\n",
    "    feld_needed = ['timestamp'\n",
    "                   ,'user_id'\n",
    "                   ,'answered_correctly'\n",
    "                   ,'content_id'\n",
    "                   ,'content_type_id'\n",
    "                   ,'prior_question_elapsed_time'\n",
    "                   ,'prior_question_had_explanation'\n",
    "                  ]\n",
    "    total_train_count = 0\n",
    "    for i in range(1):\n",
    "        if not KAGGLE_RUN:\n",
    "            train = dt.fread('./input/train.csv'\n",
    "                            ,max_nrows = 1 * 1000000\n",
    "                            ).to_pandas()\n",
    "            \n",
    "        else:\n",
    "            train = dt.fread('../input/riiid-test-answer-prediction/train.csv'\n",
    "                            ,skip_to_line = i * 10000000 + 2\n",
    "                            ,max_nrows = 10000000\n",
    "                            ).to_pandas()\n",
    "            \n",
    "\n",
    "        # Needed when skipping rows\n",
    "        train.columns = train_cols\n",
    "        train = train[feld_needed]\n",
    "        \n",
    "        # Record total train count (to ensure using all rows when batching on kaggle)\n",
    "        total_train_count += train.shape[0]\n",
    "    \n",
    "\n",
    "        # No need for validation set if running on kaggle\n",
    "        if False:\n",
    "            pass\n",
    "        else:\n",
    "            valid = None\n",
    "\n",
    "        # Changing dtype to avoid lightgbm error\n",
    "        train['prior_question_had_explanation'] = train.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "\n",
    "        # Merge with questions dataframe\n",
    "        q_cols = ['question_id', 'part', 'community', 'correct_answer', 'tags', 'n_tags'\n",
    "                 ,'tag_1', 'tag_2', 'tag_3']\n",
    "        train = pd.merge(train, questions_df[q_cols]\n",
    "                         ,left_on = 'content_id'\n",
    "                         ,right_on = 'question_id'\n",
    "                         ,how = 'left')\n",
    "\n",
    "        print('Train Feature Calculation Started - ' + str(i))\n",
    "        train = add_features(train, features_dicts, cond_probs, KAGGLE_RUN = KAGGLE_RUN, is_inference = False)\n",
    "        \n",
    "        # Only run once for model buildling\n",
    "        if not KAGGLE_RUN:\n",
    "            break\n",
    "    \n",
    "    print('Number of training rows read: ' + str(total_train_count))\n",
    "    \n",
    "    # Filter by content_type_id to discard lectures for modeling\n",
    "    if not KAGGLE_RUN:\n",
    "        train = train.loc[train.content_type_id == 0].reset_index(drop = True) \n",
    "    \n",
    "    return train, valid, questions_df, features_dicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, questions_df, features_dicts = read_and_preprocess(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riiid",
   "language": "python",
   "name": "riiid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
