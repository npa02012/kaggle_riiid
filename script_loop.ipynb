{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# N_TRAIN_ROW_TOTAL = 101230332\n",
    "# https://www.kaggle.com/spacelx/2020-r3id-clustering-question-tags/ (Version 5)\n",
    "# Decide whether or not running on Kaggle\n",
    "import os\n",
    "KAGGLE_RUN = True\n",
    "if os.path.isdir('/home/ubuntu'):\n",
    "    KAGGLE_RUN = False\n",
    "    \n",
    "if KAGGLE_RUN:\n",
    "    model_name = 'modelloop3/modelloop3.txt'\n",
    "else:\n",
    "    model_name = 'modelloop3.txt'\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datatable as dt\n",
    "\n",
    "if not KAGGLE_RUN:\n",
    "    sys.path.insert(0, './input')\n",
    "    import local_work\n",
    "    \n",
    "import riiideducation\n",
    "\n",
    "# Boto3 Setup and Download Files\n",
    "if not KAGGLE_RUN:\n",
    "    local_work = local_work.local_work()\n",
    "    local_work.download_riiid_files()\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Random seed\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion for user stats with loops\n",
    "def add_features(df, features_dicts, KAGGLE_RUN, is_inference):\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Get feature dicts\n",
    "    d_answered_correctly_u_count = features_dicts['d_answered_correctly_u_count']\n",
    "    d_answered_correctly_u_sum = features_dicts['d_answered_correctly_u_sum']\n",
    "    d_answered_correctly_prev5_u = features_dicts['d_answered_correctly_prev5_u']\n",
    "    d_elapsed_time_u_sum = features_dicts['d_elapsed_time_u_sum']\n",
    "    d_explanation_u_sum = features_dicts['d_explanation_u_sum']\n",
    "    d_answered_correctly_q_count = features_dicts['d_answered_correctly_q_count']\n",
    "    d_answered_correctly_q_sum = features_dicts['d_answered_correctly_q_sum']\n",
    "    d_elapsed_time_q_sum = features_dicts['d_elapsed_time_q_sum']\n",
    "    d_explanation_q_sum = features_dicts['d_explanation_q_sum']\n",
    "    d_answered_correctly_uq = features_dicts['d_answered_correctly_uq']\n",
    "    d_timestamp_u = features_dicts['d_timestamp_u']\n",
    "    d_timestamp_u_incorrect = features_dicts['d_timestamp_u_incorrect']\n",
    "    d_answered_correctly_up_sum = features_dicts['d_answered_correctly_up_sum']\n",
    "    d_answered_correctly_up_count = features_dicts['d_answered_correctly_up_count']\n",
    "    d_answered_correctly_uc_count = features_dicts['d_answered_correctly_uc_count']\n",
    "    d_answered_correctly_uc_sum = features_dicts['d_answered_correctly_uc_sum']\n",
    "    \n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    # Client features\n",
    "    answered_correctly_u_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    answered_correctly_prev5_u_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    elapsed_time_u_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    explanation_u_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    timestamp_u_recency_1 = np.zeros(len(df), dtype = np.float32)\n",
    "    timestamp_u_recency_2 = np.zeros(len(df), dtype = np.float32)\n",
    "    timestamp_u_recency_3 = np.zeros(len(df), dtype = np.float32)\n",
    "    timestamp_u_incorrect_recency = np.zeros(len(df), dtype = np.float32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Question features\n",
    "    answered_correctly_q_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    elapsed_time_q_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    explanation_q_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # User Question\n",
    "    answered_correctly_uq_count = np.zeros(len(df), dtype = np.int32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # User Part\n",
    "    answered_correctly_up_count = np.zeros(len(df), dtype = np.int32)\n",
    "    answered_correctly_up_avg = np.zeros(len(df), dtype = np.float32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # User Community\n",
    "    answered_correctly_uc_count = np.zeros(len(df), dtype = np.int32)\n",
    "    answered_correctly_uc_avg = np.zeros(len(df), dtype = np.float32)    \n",
    "    # -----------------------------------------------------------------------\n",
    "    \n",
    "    DF_NROW = df.shape[0]\n",
    "    for num, row in enumerate(df[['user_id'\n",
    "                                  ,'answered_correctly'\n",
    "                                  ,'content_id'\n",
    "                                  ,'prior_question_elapsed_time'\n",
    "                                  ,'prior_question_had_explanation'\n",
    "                                  ,'timestamp'\n",
    "                                  ,'part'\n",
    "                                  ,'community']].values):\n",
    "        \n",
    "        if DF_NROW > 1000000 and not KAGGLE_RUN:\n",
    "            if num % 500000 == 0:\n",
    "                print(round(num/DF_NROW, 3))\n",
    "                \n",
    "        # Client features assignation\n",
    "        # ------------------------------------------------------------------\n",
    "        if d_answered_correctly_u_count[row[0]] != 0:\n",
    "            answered_correctly_u_avg[num] = d_answered_correctly_u_sum[row[0]] / d_answered_correctly_u_count[row[0]]\n",
    "            elapsed_time_u_avg[num] = d_elapsed_time_u_sum[row[0]] / d_answered_correctly_u_count[row[0]]\n",
    "            explanation_u_avg[num] = d_explanation_u_sum[row[0]] / d_answered_correctly_u_count[row[0]]\n",
    "        else:\n",
    "            answered_correctly_u_avg[num] = np.nan\n",
    "            elapsed_time_u_avg[num] = np.nan\n",
    "            explanation_u_avg[num] = np.nan\n",
    "            \n",
    "        if len(d_timestamp_u[row[0]]) == 0:\n",
    "            timestamp_u_recency_1[num] = np.nan\n",
    "            timestamp_u_recency_2[num] = np.nan\n",
    "            timestamp_u_recency_3[num] = np.nan\n",
    "        elif len(d_timestamp_u[row[0]]) == 1:\n",
    "            timestamp_u_recency_1[num] = row[5] - d_timestamp_u[row[0]][0]\n",
    "            timestamp_u_recency_2[num] = np.nan\n",
    "            timestamp_u_recency_3[num] = np.nan\n",
    "        elif len(d_timestamp_u[row[0]]) == 2:\n",
    "            timestamp_u_recency_1[num] = row[5] - d_timestamp_u[row[0]][1]\n",
    "            timestamp_u_recency_2[num] = row[5] - d_timestamp_u[row[0]][0]\n",
    "            timestamp_u_recency_3[num] = np.nan\n",
    "        elif len(d_timestamp_u[row[0]]) == 3:\n",
    "            timestamp_u_recency_1[num] = row[5] - d_timestamp_u[row[0]][2]\n",
    "            timestamp_u_recency_2[num] = row[5] - d_timestamp_u[row[0]][1]\n",
    "            timestamp_u_recency_3[num] = row[5] - d_timestamp_u[row[0]][0]\n",
    "        \n",
    "        if len(d_timestamp_u_incorrect[row[0]]) == 0:\n",
    "            timestamp_u_incorrect_recency[num] = np.nan\n",
    "        else:\n",
    "            timestamp_u_incorrect_recency[num] = row[5] - d_timestamp_u_incorrect[row[0]][0]\n",
    "            \n",
    "        if len(d_answered_correctly_prev5_u[row[0]]) == 0:\n",
    "            answered_correctly_prev5_u_avg[num] = np.nan\n",
    "        else:\n",
    "            answered_correctly_prev5_u_avg[num] = sum(d_answered_correctly_prev5_u[row[0]])/\\\n",
    "                                                    len(d_answered_correctly_prev5_u[row[0]])\n",
    "            \n",
    "        # ------------------------------------------------------------------\n",
    "        # Question features assignation\n",
    "        if d_answered_correctly_q_count[row[2]] != 0:\n",
    "            answered_correctly_q_avg[num] = d_answered_correctly_q_sum[row[2]] / d_answered_correctly_q_count[row[2]]\n",
    "            elapsed_time_q_avg[num] = d_elapsed_time_q_sum[row[2]] / d_answered_correctly_q_count[row[2]]\n",
    "            explanation_q_avg[num] = d_explanation_q_sum[row[2]] / d_answered_correctly_q_count[row[2]]\n",
    "        else:\n",
    "            answered_correctly_q_avg[num] = np.nan\n",
    "            elapsed_time_q_avg[num] = np.nan\n",
    "            explanation_q_avg[num] = np.nan\n",
    "            \n",
    "        # ------------------------------------------------------------------\n",
    "        # Client Question assignation\n",
    "        answered_correctly_uq_count[num] = d_answered_correctly_uq[row[0]][row[2]]\n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # Client Part assignation\n",
    "        answered_correctly_up_count[num] = d_answered_correctly_up_count[row[0]][row[6]]\n",
    "        if d_answered_correctly_up_count[row[0]][row[6]] == 0:\n",
    "            answered_correctly_up_avg[num] = np.nan\n",
    "        else:\n",
    "            answered_correctly_up_avg[num] = d_answered_correctly_up_sum[row[0]][row[6]] /\\\n",
    "                                                d_answered_correctly_up_count[row[0]][row[6]]\n",
    "        # ------------------------------------------------------------------\n",
    "        # Client Community assignation\n",
    "        answered_correctly_uc_count[num] = d_answered_correctly_uc_count[row[0]][row[7]]\n",
    "        if d_answered_correctly_uc_count[row[0]][row[7]] == 0:\n",
    "            answered_correctly_uc_avg[num] = np.nan\n",
    "        else:\n",
    "            answered_correctly_uc_avg[num] = d_answered_correctly_uc_sum[row[0]][row[7]] /\\\n",
    "                                                d_answered_correctly_uc_count[row[0]][row[7]]            \n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # ------------------------------------------------------------------\n",
    "        # Client features updates\n",
    "        d_answered_correctly_u_count[row[0]] += 1\n",
    "        d_elapsed_time_u_sum[row[0]] += row[3]\n",
    "        d_explanation_u_sum[row[0]] += int(row[4])\n",
    "        if len(d_timestamp_u[row[0]]) == 3:\n",
    "            d_timestamp_u[row[0]].pop(0)\n",
    "            d_timestamp_u[row[0]].append(row[5])\n",
    "        else:\n",
    "            d_timestamp_u[row[0]].append(row[5])\n",
    "        # ------------------------------------------------------------------\n",
    "        # Question features updates\n",
    "        d_answered_correctly_q_count[row[2]] += 1\n",
    "        d_elapsed_time_q_sum[row[2]] += row[3]\n",
    "        d_explanation_q_sum[row[2]] += int(row[4])\n",
    "        # ------------------------------------------------------------------\n",
    "        # Client Question updates\n",
    "        d_answered_correctly_uq[row[0]][row[2]] += 1\n",
    "        # ------------------------------------------------------------------\n",
    "        # Client Part updates\n",
    "        d_answered_correctly_up_count[row[0]][row[6]] += 1 \n",
    "        # ------------------------------------------------------------------\n",
    "        # Client Community updates\n",
    "        d_answered_correctly_uc_count[row[0]][row[7]] += 1      \n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # Flag for training and inference. Note: this is almost identical to update_features()\n",
    "        if not is_inference:\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client features updates\n",
    "            d_answered_correctly_u_sum[row[0]] += row[1]\n",
    "            if row[1] == 0:\n",
    "                if len(d_timestamp_u_incorrect[row[0]]) == 1:\n",
    "                    d_timestamp_u_incorrect[row[0]].pop(0)\n",
    "                d_timestamp_u_incorrect[row[0]].append(row[5])\n",
    "                \n",
    "            if len(d_answered_correctly_prev5_u[row[0]]) == 5:\n",
    "                d_answered_correctly_prev5_u[row[0]].pop(0)\n",
    "            d_answered_correctly_prev5_u[row[0]].append(row[1])                \n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Question features updates\n",
    "            d_answered_correctly_q_sum[row[2]] += row[1]\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Part features updates\n",
    "            d_answered_correctly_up_sum[row[0]][row[6]] += row[1]\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Community features updates\n",
    "            d_answered_correctly_uc_sum[row[0]][row[7]] += row[1]\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "             \n",
    "            \n",
    "    user_df = pd.DataFrame({'answered_correctly_u_avg': answered_correctly_u_avg\n",
    "                            ,'elapsed_time_u_avg': elapsed_time_u_avg\n",
    "                            ,'explanation_u_avg': explanation_u_avg\n",
    "                            ,'answered_correctly_q_avg': answered_correctly_q_avg\n",
    "                            ,'answered_correctly_prev5_u_avg': answered_correctly_prev5_u_avg\n",
    "                            ,'elapsed_time_q_avg': elapsed_time_q_avg\n",
    "                            ,'explanation_q_avg': explanation_q_avg\n",
    "                            ,'answered_correctly_uq_count': answered_correctly_uq_count\n",
    "                            ,'timestamp_u_recency_1': timestamp_u_recency_1\n",
    "                            ,'timestamp_u_recency_2': timestamp_u_recency_2\n",
    "                            ,'timestamp_u_recency_3': timestamp_u_recency_3\n",
    "                            ,'timestamp_u_incorrect_recency': timestamp_u_incorrect_recency\n",
    "                            ,'answered_correctly_up_avg' : answered_correctly_up_avg\n",
    "                            ,'answered_correctly_up_count' : answered_correctly_up_count\n",
    "                            ,'answered_correctly_uc_avg' : answered_correctly_uc_avg\n",
    "                            ,'answered_correctly_uc_count' : answered_correctly_uc_count\n",
    "                           })\n",
    "    \n",
    "    # Only need to concat rows if building a model or inferring\n",
    "    if (not KAGGLE_RUN) or is_inference:\n",
    "        df = pd.concat([df, user_df], axis = 1)\n",
    "    return df\n",
    "        \n",
    "def update_features(df, features_dicts):\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Get feature dicts\n",
    "    d_answered_correctly_u_sum = features_dicts['d_answered_correctly_u_sum']\n",
    "    d_answered_correctly_q_sum = features_dicts['d_answered_correctly_q_sum']\n",
    "    d_timestamp_u_incorrect = features_dicts['d_timestamp_u_incorrect']\n",
    "    d_answered_correctly_prev5_u = features_dicts['d_answered_correctly_prev5_u']\n",
    "    d_answered_correctly_up_sum = features_dicts['d_answered_correctly_up_sum']\n",
    "    d_answered_correctly_uc_sum = features_dicts['d_answered_correctly_uc_sum']\n",
    "    \n",
    "    for row in df[['user_id'\n",
    "                   ,'answered_correctly'\n",
    "                   ,'content_id'\n",
    "                   ,'content_type_id'\n",
    "                   ,'timestamp'\n",
    "                   ,'part'\n",
    "                   ,'community'\n",
    "                  ]].values:\n",
    "        if row[3] == 0:\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client features updates\n",
    "            d_answered_correctly_u_sum[row[0]] += row[1]\n",
    "            if row[1] == 0:\n",
    "                if len(d_timestamp_u_incorrect[row[0]]) == 1:\n",
    "                    d_timestamp_u_incorrect[row[0]].pop(0)\n",
    "                d_timestamp_u_incorrect[row[0]].append(row[4])\n",
    "                \n",
    "            if len(d_answered_correctly_prev5_u[row[0]]) == 5:\n",
    "                d_answered_correctly_prev5_u[row[0]].pop(0)\n",
    "            d_answered_correctly_prev5_u[row[0]].append(row[1])                   \n",
    "            # ------------------------------------------------------------------\n",
    "            # Question features updates\n",
    "            d_answered_correctly_q_sum[row[2]] += row[1]\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Part features updates\n",
    "            d_answered_correctly_up_sum[row[0]][row[5]] += row[1]\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Community features updates\n",
    "            d_answered_correctly_uc_sum[row[0]][row[6]] += row[1]\n",
    "\n",
    "def read_and_preprocess(KAGGLE_RUN):\n",
    "\n",
    "    # Make feature_dicts dictionary for easy passing between functions\n",
    "    features_dicts = {\n",
    "        # Client dictionaries\n",
    "        'd_answered_correctly_u_count': defaultdict(int)\n",
    "        ,'d_answered_correctly_u_sum': defaultdict(int)\n",
    "        ,'d_answered_correctly_prev5_u': defaultdict(list)\n",
    "        ,'d_elapsed_time_u_sum': defaultdict(int)\n",
    "        ,'d_explanation_u_sum': defaultdict(int)\n",
    "        ,'d_timestamp_u': defaultdict(list)\n",
    "        ,'d_timestamp_u_incorrect': defaultdict(list)\n",
    "        \n",
    "        # Question Dictionaries\n",
    "        ,'d_answered_correctly_q_count': defaultdict(int)\n",
    "        ,'d_answered_correctly_q_sum': defaultdict(int)\n",
    "        ,'d_elapsed_time_q_sum': defaultdict(int)\n",
    "        ,'d_explanation_q_sum': defaultdict(int)\n",
    "        \n",
    "        # Client Question dictionary (how many times has the client seen the question)\n",
    "        ,'d_answered_correctly_uq': defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    }\n",
    "    \n",
    "    # Load questions\n",
    "    if not KAGGLE_RUN:\n",
    "        questions_df = local_work.get_questions_data()\n",
    "        question_cmnts = pd.read_csv('./input/question_cmnts_v5.csv')\n",
    "        question_cmnts.columns = ['question_id', 'community']\n",
    "    else:   \n",
    "        questions_df = pd.read_csv('../input/riiid-test-answer-prediction/questions.csv')\n",
    "        \n",
    "    tmp = questions_df.shape[0]\n",
    "    questions_df = questions_df.merge(question_cmnts, on = 'question_id', how = 'left')\n",
    "    assert(tmp == questions_df.shape[0])\n",
    "        \n",
    "    # Change questions dtypes\n",
    "    questions_df['part'] = questions_df['part'].astype(np.int32)\n",
    "    questions_df['bundle_id'] = questions_df['bundle_id'].astype(np.int32)\n",
    "    questions_df['community'] = questions_df['community'].astype(np.int8)\n",
    "        \n",
    "    # Need to load all columns when batching\n",
    "    train_cols = ['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
    "               'task_container_id', 'user_answer', 'answered_correctly',\n",
    "               'prior_question_elapsed_time', 'prior_question_had_explanation']\n",
    "    \n",
    "    # Columns we need\n",
    "    feld_needed = ['timestamp'\n",
    "                   ,'user_id'\n",
    "                   ,'answered_correctly'\n",
    "                   ,'content_id'\n",
    "                   ,'content_type_id'\n",
    "                   ,'prior_question_elapsed_time'\n",
    "                   ,'prior_question_had_explanation'\n",
    "                  ]\n",
    "    total_train_count = 0\n",
    "    for i in range(11):\n",
    "        if not KAGGLE_RUN:\n",
    "            N_TRAIN_ROWS = 1 * 1000000\n",
    "            train = local_work.get_train_data(feld_needed, nrow=N_TRAIN_ROWS)\n",
    "        else:\n",
    "            train = dt.fread('../input/riiid-test-answer-prediction/train.csv'\n",
    "                            ,skip_to_line = i * 10000000 + 2\n",
    "                            ,max_nrows=10000000).to_pandas()\n",
    "            train.columns = train_cols\n",
    "            train = train[feld_needed]\n",
    "        \n",
    "        total_train_count += train.shape[0]\n",
    "    \n",
    "        # Filter by content_type_id to discard lectures\n",
    "        train = train.loc[train.content_type_id == 0].reset_index(drop = True)\n",
    "\n",
    "\n",
    "        # Changing dtype to avoid lightgbm error\n",
    "        train['prior_question_had_explanation'] = train.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "\n",
    "        # Merge with questions dataframe\n",
    "        train = pd.merge(train, questions_df[['question_id', 'part', 'community']]\n",
    "                         ,left_on = 'content_id'\n",
    "                         ,right_on = 'question_id'\n",
    "                         ,how = 'left')\n",
    "\n",
    "        if not KAGGLE_RUN:\n",
    "            valid['prior_question_had_explanation'] = valid.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "            valid = pd.merge(valid, questions_df[['question_id', 'part', 'community']]\n",
    "                             ,left_on = 'content_id'\n",
    "                             ,right_on = 'question_id'\n",
    "                             ,how = 'left')\n",
    "\n",
    "        print('Train Feature Calculation Started - ' + str(i))\n",
    "        train = add_features(train, features_dicts, KAGGLE_RUN = KAGGLE_RUN, is_inference = False)\n",
    "        \n",
    "        # Only run once for model buildling\n",
    "        if not KAGGLE_RUN:\n",
    "            break\n",
    "    \n",
    "    print('Number of training rows read: ' + str(total_train_count))\n",
    "    \n",
    "    # Free up space\n",
    "    if KAGGLE_RUN:\n",
    "        del train\n",
    "        train = None\n",
    "    \n",
    "    # Add features for validation set\n",
    "    if not KAGGLE_RUN:\n",
    "        print('Valid Feature Calculation Started')\n",
    "        valid = add_features(valid, features_dicts, KAGGLE_RUN = KAGGLE_RUN, is_inference = False)\n",
    "    gc.collect()\n",
    "    \n",
    "    return train, valid, questions_df, features_dicts\n",
    "\n",
    "# Function for training and evaluation\n",
    "def train_and_evaluate(train, valid, KAGGLE_RUN, model_name):\n",
    "    \n",
    "    TARGET = 'answered_correctly'\n",
    "    FEATURES = ['prior_question_elapsed_time'\n",
    "                ,'prior_question_had_explanation'\n",
    "                ,'part'\n",
    "                ,'community'\n",
    "                ,'answered_correctly_u_avg'\n",
    "                ,'answered_correctly_prev5_u_avg'\n",
    "                ,'elapsed_time_u_avg'\n",
    "                ,'explanation_u_avg'\n",
    "                ,'answered_correctly_q_avg'\n",
    "                ,'elapsed_time_q_avg'\n",
    "                ,'explanation_q_avg'\n",
    "                ,'answered_correctly_uq_count'\n",
    "                ,'timestamp_u_recency_1'\n",
    "                ,'timestamp_u_recency_2'\n",
    "                ,'timestamp_u_recency_3'\n",
    "                ,'timestamp_u_incorrect_recency'\n",
    "                ,'answered_correctly_up_avg'\n",
    "                ,'answered_correctly_up_count'\n",
    "                ,'answered_correctly_uc_avg'\n",
    "                ,'answered_correctly_uc_count'\n",
    "               ]\n",
    "    \n",
    "    if not KAGGLE_RUN:\n",
    "        print(f'Traning with {train.shape[0]} rows and {len(FEATURES)} features')    \n",
    "        d_train = lgb.Dataset(train[FEATURES], label=train[TARGET])\n",
    "        d_valid = lgb.Dataset(valid[FEATURES], label=valid[TARGET])\n",
    "\n",
    "        params = {'objective': 'binary', \n",
    "                  'seed': SEED,\n",
    "                  'metric': 'auc',\n",
    "                  'learning_rate': .1,\n",
    "                  'num_leaves': 120,\n",
    "                  'feature_fraction': .8,\n",
    "                  'bagging_fraction': .8,\n",
    "                 }\n",
    "\n",
    "        if True:\n",
    "            model = lgb.train(\n",
    "                            params = params,\n",
    "                            train_set = d_train,\n",
    "                            num_boost_round = 10000,\n",
    "                            valid_sets = [d_train, d_valid],\n",
    "                            early_stopping_rounds = 20,\n",
    "                            verbose_eval = 50\n",
    "                            )\n",
    "            model.save_model(f'./output/' + model_name)\n",
    "            lgb.plot_importance(model, importance_type='gain')\n",
    "            lgb.plot_importance(model, importance_type='split')\n",
    "        else:\n",
    "            model = lgb.Booster(model_file='./output/' + model_name)\n",
    "            lgb.plot_importance(model, importance_type='gain')\n",
    "    else:\n",
    "        model = lgb.Booster(model_file='/kaggle/input/' + model_name)\n",
    "\n",
    "    return TARGET, FEATURES, model\n",
    "\n",
    "# Using time series api that simulates production predictions\n",
    "def inference(TARGET, FEATURES, model, questions_df, features_dicts):\n",
    "    \n",
    "    # Get api iterator and predictor\n",
    "    env = riiideducation.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    set_predict = env.predict\n",
    "    \n",
    "    previous_test_df = None\n",
    "    for (test_df, sample_prediction_df) in iter_test:\n",
    "        if previous_test_df is not None:\n",
    "            previous_test_df[TARGET] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n",
    "            update_features(previous_test_df, features_dicts)\n",
    "        previous_test_df = test_df.copy()\n",
    "        test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n",
    "        test_df['prior_question_had_explanation'] = test_df.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "        test_df = pd.merge(test_df, questions_df[['question_id', 'part', 'community']]\n",
    "                           ,left_on = 'content_id'\n",
    "                           ,right_on = 'question_id'\n",
    "                           ,how = 'left')\n",
    "        test_df[TARGET] = 0\n",
    "        test_df = add_features(test_df, features_dicts, KAGGLE_RUN = KAGGLE_RUN, is_inference = True)\n",
    "        test_df[TARGET] =  model.predict(test_df[FEATURES])\n",
    "        set_predict(test_df[['row_id', TARGET]])\n",
    "        \n",
    "    print('Job Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['user_id', 'answered_correctly', 'community', 'answered_correctly_uc_count', 'answered_correctly_uc_avg']][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining validation sets\n",
      "Validation size: 107607\n",
      "Train size: 872486\n",
      "Train Feature Calculation Started - 0\n",
      "Number of training rows read: 1000000\n",
      "Valid Feature Calculation Started\n"
     ]
    }
   ],
   "source": [
    "train, valid, questions_df, features_dicts = read_and_preprocess(KAGGLE_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning with 872486 rows and 20 features\n",
      "[LightGBM] [Info] Number of positive: 571306, number of negative: 301180\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3708\n",
      "[LightGBM] [Info] Number of data points in the train set: 872486, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654802 -> initscore=0.640217\n",
      "[LightGBM] [Info] Start training from score 0.640217\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-84add3959990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTARGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKAGGLE_RUN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-67bdf8cd27a4>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(train, valid, KAGGLE_RUN, model_name)\u001b[0m\n\u001b[1;32m    448\u001b[0m                             \u001b[0mvalid_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                             \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                             \u001b[0mverbose_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                             )\n\u001b[1;32m    452\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./output/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_riiid/venv/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_riiid/venv/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m         \"\"\"\n\u001b[0;32m-> 2686\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_riiid/venv/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   3214\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3216\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   3217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3218\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TARGET, FEATURES, model = train_and_evaluate(train, valid, KAGGLE_RUN, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['community', 'part'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-216fe2641ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestions_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-67bdf8cd27a4>\u001b[0m in \u001b[0;36minference\u001b[0;34m(TARGET, FEATURES, model, questions_df, features_dicts)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_test_df\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mprevious_test_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prior_group_answers_correct\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mupdate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_test_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0mprevious_test_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content_type_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-67bdf8cd27a4>\u001b[0m in \u001b[0;36mupdate_features\u001b[0;34m(df, features_dicts)\u001b[0m\n\u001b[1;32m    229\u001b[0m                    \u001b[0;34m,\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                    \u001b[0;34m,\u001b[0m\u001b[0;34m'part'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                    \u001b[0;34m,\u001b[0m\u001b[0;34m'community'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                   ]].values:\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_riiid/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_riiid/venv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_riiid/venv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['community', 'part'] not in index\""
     ]
    }
   ],
   "source": [
    "inference(TARGET, FEATURES, model, questions_df, features_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riiid",
   "language": "python",
   "name": "riiid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
